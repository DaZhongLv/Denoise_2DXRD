{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate Noise2Self on Leo-cropped dataset (reconstructable, counts-space)\n",
        "\n",
        "This notebook is for evaluating denoising on a 4D scan stack stored in HDF5 with shape `(sy, sx, dety, detx)`.\n",
        "\n",
        "You can:\n",
        "- interactively view **input / denoised / residual** in **counts** (or `log1p(counts)`)\n",
        "- overlay **center-of-mass (CoM)** markers for input vs denoised and see the shift\n",
        "- compute **full-scan CoM overlay maps** (fast path if you have a GPU)\n",
        "- do **Option B (CPU-only)**: compare **original H5 vs denoised H5** without running the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "repo root: d:\\Project_PostDoc\\Hackathon\\noise2self\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import ipywidgets as widgets\n",
        "import torch\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "# ---- Ensure repo root is importable (so `import mask`, `import models.*` work) ----\n",
        "_repo = None\n",
        "for p in [Path.cwd(), *Path.cwd().parents]:\n",
        "    if (p / \"mask.py\").exists() and (p / \"train_noise2self.py\").exists():\n",
        "        _repo = p\n",
        "        break\n",
        "if _repo is None:\n",
        "    raise RuntimeError(\n",
        "        \"Could not find repo root. Run this notebook from inside the repo, \"\n",
        "        \"or edit the path logic to point at the noise2self repository.\"\n",
        "    )\n",
        "if str(_repo) not in sys.path:\n",
        "    sys.path.insert(0, str(_repo))\n",
        "\n",
        "from mask import Masker\n",
        "from models.unet import Unet\n",
        "from models.babyunet import BabyUnet\n",
        "from models.dncnn import DnCNN\n",
        "from models.singleconv import SingleConvolution\n",
        "\n",
        "print(\"repo root:\", _repo)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "H5_PATH: D:\\Project_PostDoc\\Hackathon\\denoising_Dataset\\data\\processed_win00_left512.h5\n",
            "H5 exists: True\n",
            "CKPT_PATH: D:\\Project_PostDoc\\Hackathon\\old_runs\\ckpt_best.pt\n",
            "CKPT exists: True\n",
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "# ---- Paths (edit these) ----\n",
        "# IMPORTANT: this notebook runs on *your current machine*.\n",
        "# - If the .h5 lives on the cluster under /ptmp, either copy it locally or run this notebook on the cluster.\n",
        "\n",
        "H5_PATHS = [\n",
        "    r\"D:\\Project_PostDoc\\Hackathon\\denoising_Dataset\\data\\processed_win00_left512.h5\"\n",
        "]\n",
        "H5_PATH = next((p for p in H5_PATHS if os.path.exists(p)), H5_PATHS[-1])\n",
        "\n",
        "# Checkpoint (local path if you've copied it; otherwise run this notebook where ckpt is accessible)\n",
        "CKPT_PATH = r\"D:\\Project_PostDoc\\Hackathon\\old_runs\\ckpt_best.pt\"\n",
        "\n",
        "# HDF5 dataset key candidates\n",
        "H5_KEY_CANDIDATES = [\"data\", \"/data\", \"X\", \"/X\", \"img\", \"/img\"]\n",
        "\n",
        "# Device (GPU if available, otherwise CPU)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Display defaults\n",
        "CMAP = \"terrain\"\n",
        "RESID_CMAP = \"coolwarm\"\n",
        "\n",
        "# Percentiles used for visualization\n",
        "DEFAULT_VMAX_PCT = 99.9\n",
        "DEFAULT_RESID_PCT = 99.0\n",
        "\n",
        "print(\"H5_PATH:\", H5_PATH)\n",
        "print(\"H5 exists:\", os.path.exists(H5_PATH))\n",
        "print(\"CKPT_PATH:\", CKPT_PATH)\n",
        "print(\"CKPT exists:\", os.path.exists(CKPT_PATH))\n",
        "print(\"device:\", DEVICE)\n",
        "\n",
        "if not os.path.exists(H5_PATH):\n",
        "    raise FileNotFoundError(\n",
        "        \"H5 file not found. If you trained/saved it on the cluster under /ptmp, either:\\n\"\n",
        "        \"  (1) copy it to your local machine and update H5_PATHS, or\\n\"\n",
        "        \"  (2) run this notebook on the cluster where /ptmp is visible.\\n\\n\"\n",
        "        f\"Tried: {H5_PATHS}\"\n",
        "    )\n",
        "\n",
        "if not os.path.exists(CKPT_PATH):\n",
        "    raise FileNotFoundError(\n",
        "        \"Checkpoint not found at CKPT_PATH. Update CKPT_PATH to point to ckpt_epoch*.pt or ckpt_best.pt\"\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset key: /img\n",
            "shape (sy,sx,dety,detx): (141, 121, 512, 512)\n",
            "dtype: float32\n",
            "has real_space_sum_thresholded: False\n"
          ]
        }
      ],
      "source": [
        "# ---- Open HDF5 lazily ----\n",
        "_h5 = h5py.File(H5_PATH, \"r\")\n",
        "\n",
        "_dset = None\n",
        "for k in H5_KEY_CANDIDATES:\n",
        "    if k in _h5:\n",
        "        _dset = _h5[k]\n",
        "        break\n",
        "assert _dset is not None, f\"Could not find dataset key in {list(_h5.keys())}\"\n",
        "\n",
        "sy, sx, dety, detx = (int(x) for x in _dset.shape)\n",
        "dtype = _dset.dtype\n",
        "\n",
        "# Optional precomputed maps (if created by SaveThresholdedFrames.ipynb)\n",
        "_total_real = _h5[\"real_space_sum_thresholded\"][:] if \"real_space_sum_thresholded\" in _h5 else None\n",
        "\n",
        "print(\"dataset key:\", _dset.name)\n",
        "print(\"shape (sy,sx,dety,detx):\", (sy, sx, dety, detx))\n",
        "print(\"dtype:\", dtype)\n",
        "print(\"has real_space_sum_thresholded:\", _total_real is not None)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded ckpt: D:\\Project_PostDoc\\Hackathon\\old_runs\\ckpt_best.pt\n",
            "model: unet in_ch= 1 out_ch= 1\n",
            "masker: width=4 mode=interpolate include_mask_as_input=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\k.umate\\AppData\\Local\\Temp\\ipykernel_6112\\575220976.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(CKPT_PATH, map_location=\"cpu\")\n"
          ]
        }
      ],
      "source": [
        "# ---- Load checkpoint + build model ----\n",
        "ckpt = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
        "cfg = ckpt.get(\"config\", {}) or {}\n",
        "\n",
        "model_name = str(cfg.get(\"model\", \"unet\")).lower()\n",
        "in_ch = int(cfg.get(\"in_channels\", 1))\n",
        "out_ch = int(cfg.get(\"out_channels\", 1))\n",
        "include_mask_as_input = bool(cfg.get(\"include_mask_as_input\", False))\n",
        "masker_width = int(cfg.get(\"masker_width\", 4))\n",
        "masker_mode = str(cfg.get(\"masker_mode\", \"interpolate\"))\n",
        "\n",
        "if model_name == \"unet\":\n",
        "    model = Unet(in_ch, out_ch)\n",
        "elif model_name in {\"babyunet\", \"baby-unet\"}:\n",
        "    model = BabyUnet(in_ch, out_ch)\n",
        "elif model_name in {\"dncnn\"}:\n",
        "    model = DnCNN(channels=in_ch)  # repo's notebook-style API\n",
        "elif model_name in {\"conv\", \"convolution\", \"singleconv\"}:\n",
        "    model = SingleConvolution(in_ch, out_ch, width=3)\n",
        "else:\n",
        "    raise ValueError(f\"Unknown model in ckpt config: {model_name!r}\")\n",
        "\n",
        "model.load_state_dict(ckpt[\"state_dict\"], strict=True)\n",
        "model.to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "masker = Masker(\n",
        "    width=masker_width,\n",
        "    mode=masker_mode,\n",
        "    infer_single_pass=True,\n",
        "    include_mask_as_input=include_mask_as_input,\n",
        ")\n",
        "\n",
        "print(\"Loaded ckpt:\", CKPT_PATH)\n",
        "print(\"model:\", model_name, \"in_ch=\", in_ch, \"out_ch=\", out_ch)\n",
        "print(\"masker:\", f\"width={masker_width}\", f\"mode={masker_mode}\", f\"include_mask_as_input={include_mask_as_input}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _pad_to_multiple_2d(x: np.ndarray, mult: int = 16, *, mode: str = \"constant\", constant_values: float = 0.0):\n",
        "    \"\"\"Pad a (H,W) array so H and W are divisible by mult. Returns (x_pad, pads).\"\"\"\n",
        "    assert x.ndim == 2\n",
        "    h, w = x.shape\n",
        "    pad_h = (mult - (h % mult)) % mult\n",
        "    pad_w = (mult - (w % mult)) % mult\n",
        "\n",
        "    pad_top = pad_h // 2\n",
        "    pad_bot = pad_h - pad_top\n",
        "    pad_left = pad_w // 2\n",
        "    pad_right = pad_w - pad_left\n",
        "\n",
        "    if pad_h == 0 and pad_w == 0:\n",
        "        return x, (0, 0, 0, 0)\n",
        "\n",
        "    x_pad = np.pad(\n",
        "        x,\n",
        "        ((pad_top, pad_bot), (pad_left, pad_right)),\n",
        "        mode=mode,\n",
        "        constant_values=constant_values if mode == \"constant\" else 0.0,\n",
        "    )\n",
        "    return x_pad, (pad_top, pad_bot, pad_left, pad_right)\n",
        "\n",
        "\n",
        "def _unpad_2d(x_pad: np.ndarray, pads):\n",
        "    pad_top, pad_bot, pad_left, pad_right = pads\n",
        "    if pad_top == pad_bot == pad_left == pad_right == 0:\n",
        "        return x_pad\n",
        "    h, w = x_pad.shape\n",
        "    return x_pad[pad_top : h - pad_bot, pad_left : w - pad_right]\n",
        "\n",
        "\n",
        "# ---- Normalization/scaling (match training config stored in checkpoint) ----\n",
        "NORMALIZE_MODE = str(cfg.get(\"normalize\", \"percentile\")).lower()\n",
        "SCALE_INTEGERS = bool(cfg.get(\"scale_integers\", True))\n",
        "\n",
        "\n",
        "def _normalize_percentile_2d(x: np.ndarray, *, pmin: float = 1.0, pmax: float = 99.0, eps: float = 1e-6):\n",
        "    lo = float(np.percentile(x, pmin))\n",
        "    hi = float(np.percentile(x, pmax))\n",
        "    return (x - lo) / (hi - lo + eps)\n",
        "\n",
        "\n",
        "def _normalize_minmax_2d(x: np.ndarray, *, eps: float = 1e-6) -> np.ndarray:\n",
        "    mn = float(np.min(x))\n",
        "    mx = float(np.max(x))\n",
        "    return (x - mn) / (mx - mn + eps)\n",
        "\n",
        "\n",
        "def to_model_space(x_counts: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Convert float32 counts (H,W) into the numeric space the model expects.\"\"\"\n",
        "    x = np.asarray(x_counts, dtype=np.float32)\n",
        "\n",
        "    if SCALE_INTEGERS and np.issubdtype(dtype, np.integer):\n",
        "        info = np.iinfo(dtype)\n",
        "        x = x / float(info.max)\n",
        "\n",
        "    if NORMALIZE_MODE == \"percentile\":\n",
        "        x = _normalize_percentile_2d(x, pmin=1.0, pmax=99.0)\n",
        "    elif NORMALIZE_MODE == \"minmax\":\n",
        "        x = _normalize_minmax_2d(x)\n",
        "    elif NORMALIZE_MODE == \"none\":\n",
        "        pass\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown normalize mode in ckpt config: {NORMALIZE_MODE!r}\")\n",
        "\n",
        "    return np.asarray(x, dtype=np.float32)\n",
        "\n",
        "\n",
        "def load_frame_counts(y: int, x: int) -> np.ndarray:\n",
        "    \"\"\"Load one detector frame from HDF5 as float32 counts (no extra normalization).\"\"\"\n",
        "    arr = _dset[int(y), int(x)]\n",
        "    return np.asarray(arr, dtype=np.float32)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def denoise_frame_model_space(x_counts_2d: np.ndarray, *, pad_mode: str = \"constant\") -> np.ndarray:\n",
        "    \"\"\"Run Noise2Self inference for a single (H,W) float32 counts image.\n",
        "\n",
        "    Returns model output in *model space* (same space as training input/target).\n",
        "    \"\"\"\n",
        "    x_model = to_model_space(x_counts_2d)\n",
        "    x_pad, pads = _pad_to_multiple_2d(x_model, 16, mode=pad_mode, constant_values=0.0)\n",
        "\n",
        "    xt = torch.from_numpy(x_pad[None, None, ...]).to(DEVICE)  # (1,1,H,W)\n",
        "    use_amp = bool(DEVICE.type == \"cuda\")\n",
        "    with torch.amp.autocast(device_type=DEVICE.type, enabled=use_amp):\n",
        "        yt = masker.infer_full_image(xt, model)\n",
        "    y = yt.detach().to(\"cpu\").float().numpy()[0, 0]\n",
        "    y = _unpad_2d(y, pads)\n",
        "    return np.asarray(y, dtype=np.float32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GLOBAL_VMAX_COUNTS (p99.9 from sample): 1.541103482246399\n"
          ]
        }
      ],
      "source": [
        "# Optional: estimate a global vmax from a small sample (for stable colorbars)\n",
        "\n",
        "def estimate_global_vmax(*, n_samples: int = 12, vmax_pct: float = 99.9, seed: int = 0) -> float:\n",
        "    rng = np.random.default_rng(int(seed))\n",
        "    ys = rng.integers(0, sy, size=n_samples)\n",
        "    xs = rng.integers(0, sx, size=n_samples)\n",
        "\n",
        "    vals = []\n",
        "    for y, x in zip(ys, xs):\n",
        "        frame = load_frame_counts(int(y), int(x))\n",
        "        vals.append(frame.ravel())\n",
        "    flat = np.concatenate(vals, axis=0)\n",
        "    return float(np.percentile(flat, float(vmax_pct)))\n",
        "\n",
        "\n",
        "GLOBAL_VMAX_COUNTS = estimate_global_vmax(n_samples=12, vmax_pct=99.9, seed=0)\n",
        "print(\"GLOBAL_VMAX_COUNTS (p99.9 from sample):\", GLOBAL_VMAX_COUNTS)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8eb124063e4c4a7ca8b08e09856290c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HBox(children=(IntSlider(value=40, description='x', max=120, style=SliderStyle(description_widt…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b365292609b94dd2938318f10f9f5d43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def _compute_vmin_vmax(\n",
        "    *,\n",
        "    mode: str,\n",
        "    input_counts: np.ndarray,\n",
        "    denoised_counts: np.ndarray,\n",
        "    vmax_pct: float,\n",
        "    log_view: bool,\n",
        "):\n",
        "    \"\"\"Return (vmin_in, vmax_in, vmin_dn, vmax_dn) for display.\"\"\"\n",
        "    mode = str(mode)\n",
        "    vmax_pct = float(vmax_pct)\n",
        "\n",
        "    if log_view:\n",
        "        in_view = np.log1p(np.clip(input_counts, 0, None))\n",
        "        dn_view = np.log1p(np.clip(denoised_counts, 0, None))\n",
        "    else:\n",
        "        in_view = input_counts\n",
        "        dn_view = denoised_counts\n",
        "\n",
        "    if mode == \"global\":\n",
        "        vmax_in = float(np.log1p(GLOBAL_VMAX_COUNTS)) if log_view else float(GLOBAL_VMAX_COUNTS)\n",
        "        return 0.0, vmax_in, 0.0, vmax_in\n",
        "\n",
        "    if mode == \"per_frame\":\n",
        "        vmax_in = float(np.percentile(in_view, vmax_pct))\n",
        "        vmax_dn = float(np.percentile(dn_view, vmax_pct))\n",
        "        return 0.0, vmax_in, 0.0, vmax_dn\n",
        "\n",
        "    if mode == \"shared\":\n",
        "        vmax_shared = float(np.percentile(np.concatenate([in_view.ravel(), dn_view.ravel()]), vmax_pct))\n",
        "        return 0.0, vmax_shared, 0.0, vmax_shared\n",
        "\n",
        "    raise ValueError(\"mode must be one of: global, per_frame, shared\")\n",
        "\n",
        "\n",
        "# ---- CoM helpers (no SciPy dependency) ----\n",
        "COM_THRESH_PCT = 99.999\n",
        "\n",
        "\n",
        "def _threshold_for_com(img: np.ndarray, pct: float = COM_THRESH_PCT) -> np.ndarray:\n",
        "    x = np.asarray(img, dtype=np.float32)\n",
        "    x = np.clip(x, 0.0, None)\n",
        "    thr = float(np.percentile(x, float(pct)))\n",
        "    x = x.copy()\n",
        "    x[x < thr] = 0.0\n",
        "    return x\n",
        "\n",
        "\n",
        "def _center_of_mass_2d(img: np.ndarray) -> tuple[float, float]:\n",
        "    x = np.asarray(img, dtype=np.float64)\n",
        "    x = np.clip(x, 0.0, None)\n",
        "    s = float(x.sum())\n",
        "    if not np.isfinite(s) or s <= 0.0:\n",
        "        return float(\"nan\"), float(\"nan\")\n",
        "    yy, xx = np.indices(x.shape)\n",
        "    yc = float((yy * x).sum() / s)\n",
        "    xc = float((xx * x).sum() / s)\n",
        "    return yc, xc\n",
        "\n",
        "\n",
        "def _model_to_counts(den_model: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Convert model output back to counts when reconstructable.\n",
        "\n",
        "    - If normalize='none' and scale_integers=False: output is already counts.\n",
        "    - If normalize='none' and scale_integers=True: multiply by dtype max.\n",
        "    - Otherwise: no unique inverse; return a best-effort scaled output.\n",
        "    \"\"\"\n",
        "    den_model = np.asarray(den_model, dtype=np.float32)\n",
        "\n",
        "    if NORMALIZE_MODE != \"none\":\n",
        "        # No unique inverse: keep best-effort scaling so plots are still usable.\n",
        "        if SCALE_INTEGERS and np.issubdtype(dtype, np.integer):\n",
        "            return den_model * float(np.iinfo(dtype).max)\n",
        "        return den_model\n",
        "\n",
        "    if SCALE_INTEGERS and np.issubdtype(dtype, np.integer):\n",
        "        return den_model * float(np.iinfo(dtype).max)\n",
        "\n",
        "    return den_model\n",
        "\n",
        "\n",
        "def interactive_plot(\n",
        "    y: int,\n",
        "    x: int,\n",
        "    *,\n",
        "    view: str,\n",
        "    scale_mode: str,\n",
        "    vmax_pct: float,\n",
        "    resid_pct: float,\n",
        "    pad_mode: str,\n",
        "):\n",
        "    input_counts = load_frame_counts(y, x)\n",
        "    den_model = denoise_frame_model_space(input_counts, pad_mode=pad_mode)\n",
        "    den_counts = _model_to_counts(den_model)\n",
        "\n",
        "    if view == \"counts\":\n",
        "        in_view = input_counts\n",
        "        dn_view = den_counts\n",
        "        log_view = False\n",
        "    elif view == \"log1p\":\n",
        "        in_view = input_counts\n",
        "        dn_view = den_counts\n",
        "        log_view = True\n",
        "    else:\n",
        "        raise ValueError(\"view must be one of: counts, log1p\")\n",
        "\n",
        "    vmin_in, vmax_in, vmin_dn, vmax_dn = _compute_vmin_vmax(\n",
        "        mode=scale_mode,\n",
        "        input_counts=in_view if not log_view else input_counts,\n",
        "        denoised_counts=dn_view,\n",
        "        vmax_pct=vmax_pct,\n",
        "        log_view=(view == \"log1p\"),\n",
        "    )\n",
        "\n",
        "    resid = in_view - dn_view\n",
        "    r = float(np.percentile(np.abs(resid), float(resid_pct)))\n",
        "\n",
        "    in_thr = _threshold_for_com(input_counts)\n",
        "    dn_thr = _threshold_for_com(den_counts)\n",
        "    yc_in, xc_in = _center_of_mass_2d(in_thr)\n",
        "    yc_dn, xc_dn = _center_of_mass_2d(dn_thr)\n",
        "    dy = yc_dn - yc_in\n",
        "    dx = xc_dn - xc_in\n",
        "\n",
        "    fig, ax = plt.subplots(1, 4, figsize=(16, 5))\n",
        "\n",
        "    # Panel 1: real-space sum map (if available)\n",
        "    if _total_real is not None:\n",
        "        im0 = ax[0].imshow(_total_real, cmap=\"viridis\", vmax=np.percentile(_total_real, 99))\n",
        "        ax[0].scatter(x, y, color=\"cyan\", marker=\"x\", s=120, linewidth=3)\n",
        "        ax[0].set_title(f\"Real-space sum (y={y}, x={x})\")\n",
        "        plt.colorbar(im0, ax=ax[0], fraction=0.046, pad=0.04)\n",
        "    else:\n",
        "        ax[0].axis(\"off\")\n",
        "        ax[0].set_title(\"real_space_sum_thresholded\\n(not in HDF5)\")\n",
        "\n",
        "    # Panel 2: input\n",
        "    if view == \"log1p\":\n",
        "        im1 = ax[1].imshow(np.log1p(np.clip(in_view, 0, None)), cmap=CMAP, vmin=vmin_in, vmax=vmax_in)\n",
        "        ax[1].set_title(\"Input (log1p counts)\")\n",
        "    else:\n",
        "        im1 = ax[1].imshow(in_view, cmap=CMAP, vmin=vmin_in, vmax=vmax_in)\n",
        "        ax[1].set_title(\"Input (counts)\")\n",
        "    if np.isfinite(yc_in) and np.isfinite(xc_in):\n",
        "        ax[1].scatter([xc_in], [yc_in], s=120, marker=\"o\", facecolors=\"none\", edgecolors=\"cyan\", linewidths=2)\n",
        "    plt.colorbar(im1, ax=ax[1], fraction=0.046, pad=0.04)\n",
        "\n",
        "    # Panel 3: denoised\n",
        "    if view == \"log1p\":\n",
        "        im2 = ax[2].imshow(np.log1p(np.clip(dn_view, 0, None)), cmap=CMAP, vmin=vmin_dn, vmax=vmax_dn)\n",
        "        ax[2].set_title(\"Denoised (log1p counts)\")\n",
        "    else:\n",
        "        im2 = ax[2].imshow(dn_view, cmap=CMAP, vmin=vmin_dn, vmax=vmax_dn)\n",
        "        ax[2].set_title(\"Denoised (counts)\")\n",
        "    if np.isfinite(yc_dn) and np.isfinite(xc_dn):\n",
        "        ax[2].scatter([xc_dn], [yc_dn], s=120, marker=\"x\", c=\"magenta\", linewidths=3)\n",
        "    if np.isfinite(yc_in) and np.isfinite(xc_in):\n",
        "        ax[2].scatter([xc_in], [yc_in], s=120, marker=\"o\", facecolors=\"none\", edgecolors=\"cyan\", linewidths=2)\n",
        "    if np.isfinite(dx) and np.isfinite(dy):\n",
        "        ax[2].text(\n",
        "            0.02,\n",
        "            0.98,\n",
        "            f\"ΔCoM: dx={dx:+.2f}, dy={dy:+.2f} px\",\n",
        "            transform=ax[2].transAxes,\n",
        "            ha=\"left\",\n",
        "            va=\"top\",\n",
        "            color=\"white\",\n",
        "            bbox=dict(facecolor=\"black\", alpha=0.5, edgecolor=\"none\"),\n",
        "        )\n",
        "    plt.colorbar(im2, ax=ax[2], fraction=0.046, pad=0.04)\n",
        "\n",
        "    # Panel 4: residual\n",
        "    im3 = ax[3].imshow(resid, cmap=RESID_CMAP, vmin=-r, vmax=r)\n",
        "    ax[3].set_title(f\"Residual (±p{resid_pct} |.|)\\nCoM thr p{COM_THRESH_PCT}\")\n",
        "    plt.colorbar(im3, ax=ax[3], fraction=0.046, pad=0.04)\n",
        "\n",
        "    for a in ax:\n",
        "        a.set_xticks([])\n",
        "        a.set_yticks([])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Widgets\n",
        "x_slider = widgets.IntSlider(value=min(40, sx - 1), min=0, max=sx - 1, step=1, description=\"x\", style={\"description_width\": \"initial\"})\n",
        "y_slider = widgets.IntSlider(value=min(44, sy - 1), min=0, max=sy - 1, step=1, description=\"y\", style={\"description_width\": \"initial\"})\n",
        "\n",
        "view_dd = widgets.Dropdown(options=[\"counts\", \"log1p\"], value=\"counts\", description=\"view\")\n",
        "scale_dd = widgets.Dropdown(options=[\"shared\", \"global\", \"per_frame\"], value=\"shared\", description=\"scale\")\n",
        "\n",
        "vmax_pct_slider = widgets.FloatSlider(value=DEFAULT_VMAX_PCT, min=90.0, max=99.99, step=0.01, description=\"vmax %\")\n",
        "resid_pct_slider = widgets.FloatSlider(value=DEFAULT_RESID_PCT, min=90.0, max=99.99, step=0.01, description=\"resid %\")\n",
        "\n",
        "pad_dd = widgets.Dropdown(options=[\"constant\", \"reflect\", \"edge\"], value=\"constant\", description=\"pad\")\n",
        "\n",
        "ui = widgets.VBox([\n",
        "    widgets.HBox([x_slider, y_slider]),\n",
        "    widgets.HBox([view_dd, scale_dd, pad_dd]),\n",
        "    widgets.HBox([vmax_pct_slider, resid_pct_slider]),\n",
        "])\n",
        "\n",
        "out = widgets.interactive_output(\n",
        "    interactive_plot,\n",
        "    {\n",
        "        \"x\": x_slider,\n",
        "        \"y\": y_slider,\n",
        "        \"view\": view_dd,\n",
        "        \"scale_mode\": scale_dd,\n",
        "        \"vmax_pct\": vmax_pct_slider,\n",
        "        \"resid_pct\": resid_pct_slider,\n",
        "        \"pad_mode\": pad_dd,\n",
        "    },\n",
        ")\n",
        "\n",
        "display(ui, out)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # ---- Fast full-scan CoM overlay (row-wise HDF5 + batched inference) ----\n",
        "# # If you are CPU-only, this can still take a while.\n",
        "# # For a quick test set MAX_Y_ROWS=5.\n",
        "\n",
        "# from pathlib import Path\n",
        "\n",
        "# try:\n",
        "#     from tqdm.auto import tqdm\n",
        "# except Exception:\n",
        "#     tqdm = None\n",
        "\n",
        "# CACHE_DIR = Path(\".cache\")\n",
        "# CACHE_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# MAX_Y_ROWS = 5  # set to None for all rows\n",
        "# BATCH_INFER = 16\n",
        "# USE_CACHE = True\n",
        "# USE_AMP = bool(DEVICE.type == \"cuda\")\n",
        "\n",
        "# cache_path = CACHE_DIR / (\n",
        "#     f\"com_maps_model_pct{COM_THRESH_PCT}_orig{Path(H5_PATH).stem}_ckpt{Path(CKPT_PATH).stem}_by{BATCH_INFER}.npz\"\n",
        "# )\n",
        "\n",
        "\n",
        "# def _make_com_map_from_positions(pos_list, shape_hw):\n",
        "#     m = np.zeros(shape_hw, dtype=np.float32)\n",
        "#     for yc, xc in pos_list:\n",
        "#         if not (np.isfinite(yc) and np.isfinite(xc)):\n",
        "#             continue\n",
        "#         iy = int(round(float(yc)))\n",
        "#         ix = int(round(float(xc)))\n",
        "#         if 0 <= iy < shape_hw[0] and 0 <= ix < shape_hw[1]:\n",
        "#             m[iy, ix] = 1.0\n",
        "#     return m\n",
        "\n",
        "\n",
        "# def _denoise_batch_counts(frames_counts_bhw: np.ndarray) -> np.ndarray:\n",
        "#     frames = np.asarray(frames_counts_bhw, dtype=np.float32)\n",
        "\n",
        "#     # Fast path for reconstructable runs: model space is counts space\n",
        "#     if NORMALIZE_MODE == \"none\" and (not SCALE_INTEGERS):\n",
        "#         x_model = frames\n",
        "#     else:\n",
        "#         x_model = np.stack([to_model_space(frames[i]) for i in range(frames.shape[0])], axis=0)\n",
        "\n",
        "#     b, h, w = x_model.shape\n",
        "#     pad_h = (16 - (h % 16)) % 16\n",
        "#     pad_w = (16 - (w % 16)) % 16\n",
        "#     pad_top = pad_h // 2\n",
        "#     pad_bot = pad_h - pad_top\n",
        "#     pad_left = pad_w // 2\n",
        "#     pad_right = pad_w - pad_left\n",
        "\n",
        "#     if pad_h or pad_w:\n",
        "#         x_pad = np.pad(\n",
        "#             x_model,\n",
        "#             ((0, 0), (pad_top, pad_bot), (pad_left, pad_right)),\n",
        "#             mode=\"constant\",\n",
        "#             constant_values=0.0,\n",
        "#         )\n",
        "#     else:\n",
        "#         x_pad = x_model\n",
        "\n",
        "#     xt = torch.from_numpy(x_pad[:, None, ...]).to(DEVICE)\n",
        "#     with torch.no_grad():\n",
        "#         with torch.amp.autocast(device_type=DEVICE.type, enabled=USE_AMP):\n",
        "#             yt = masker.infer_full_image(xt, model)\n",
        "\n",
        "#     y = yt.detach().to(\"cpu\").float().numpy()[:, 0]\n",
        "\n",
        "#     if pad_h or pad_w:\n",
        "#         y = y[:, pad_top : y.shape[1] - pad_bot, pad_left : y.shape[2] - pad_right]\n",
        "\n",
        "#     return np.stack([_model_to_counts(y[i]) for i in range(y.shape[0])], axis=0).astype(np.float32)\n",
        "\n",
        "\n",
        "# if USE_CACHE and cache_path.exists():\n",
        "#     data = np.load(cache_path)\n",
        "#     COM_MAP_INPUT = data[\"com_map_input\"]\n",
        "#     COM_MAP_DENOISED = data[\"com_map_denoised\"]\n",
        "#     print(\"Loaded cached CoM overlays:\", cache_path)\n",
        "# else:\n",
        "#     y_total = int(sy)\n",
        "#     y_do = y_total if MAX_Y_ROWS is None else min(int(MAX_Y_ROWS), y_total)\n",
        "\n",
        "#     pos_in = []\n",
        "#     pos_dn = []\n",
        "\n",
        "#     y_iter = range(y_do)\n",
        "#     if tqdm is not None:\n",
        "#         y_iter = tqdm(y_iter, total=y_do, desc=f\"CoM overlays (rows, device={DEVICE.type}, batch={BATCH_INFER})\")\n",
        "\n",
        "#     for yy in y_iter:\n",
        "#         row = np.asarray(_dset[int(yy), :, :, :], dtype=np.float32)  # (sx,H,W)\n",
        "\n",
        "#         for xx in range(int(sx)):\n",
        "#             pos_in.append(_center_of_mass_2d(_threshold_for_com(row[xx])))\n",
        "\n",
        "#         for x0 in range(0, int(sx), int(BATCH_INFER)):\n",
        "#             x1 = min(int(sx), x0 + int(BATCH_INFER))\n",
        "#             den_row = _denoise_batch_counts(row[x0:x1])\n",
        "#             for k in range(den_row.shape[0]):\n",
        "#                 pos_dn.append(_center_of_mass_2d(_threshold_for_com(den_row[k])))\n",
        "\n",
        "#     COM_MAP_INPUT = _make_com_map_from_positions(pos_in, (dety, detx))\n",
        "#     COM_MAP_DENOISED = _make_com_map_from_positions(pos_dn, (dety, detx))\n",
        "\n",
        "#     np.savez_compressed(\n",
        "#         cache_path,\n",
        "#         com_map_input=COM_MAP_INPUT,\n",
        "#         com_map_denoised=COM_MAP_DENOISED,\n",
        "#         ckpt_path=str(CKPT_PATH),\n",
        "#         h5_path=str(H5_PATH),\n",
        "#         com_thresh_pct=np.float32(COM_THRESH_PCT),\n",
        "#         batch_infer=np.int32(BATCH_INFER),\n",
        "#         device=str(DEVICE),\n",
        "#         max_y_rows=(-1 if MAX_Y_ROWS is None else int(MAX_Y_ROWS)),\n",
        "#     )\n",
        "#     print(\"Saved cached CoM overlays:\", cache_path)\n",
        "\n",
        "# fig, ax = plt.subplots(1, 2, figsize=(10, 4), sharex=True, sharey=True)\n",
        "# ax[0].imshow(COM_MAP_INPUT, cmap=\"gray\")\n",
        "# ax[0].set_title(\"CoM overlay: input frames\")\n",
        "# ax[1].imshow(COM_MAP_DENOISED, cmap=\"gray\")\n",
        "# ax[1].set_title(\"CoM overlay: denoised (model)\")\n",
        "# for a in ax:\n",
        "#     a.set_xticks([])\n",
        "#     a.set_yticks([])\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f777691934dc432b9a25748d0c0118b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "CoM overlays from H5 (orig vs denoised):   0%|          | 0/141 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ---- Option B (CPU-friendly): CoM overlay comparison using ORIGINAL vs DENOISED HDF5 ----\n",
        "# This cell does *no model inference*. It compares:\n",
        "#   - original frames from H5_PATH\n",
        "#   - denoised frames from a separate DENOISED_H5_PATH\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    from tqdm.auto import tqdm\n",
        "except Exception:\n",
        "    tqdm = None\n",
        "\n",
        "DENOISED_H5_PATHS = [\n",
        "    r\"D:\\Project_PostDoc\\Hackathon\\old_runs\\denoised.h5\"\n",
        "]\n",
        "DENOISED_H5_PATH = next((p for p in DENOISED_H5_PATHS if p and os.path.exists(p)), None)\n",
        "\n",
        "if DENOISED_H5_PATH is None:\n",
        "    raise FileNotFoundError(\"Set DENOISED_H5_PATHS to point to your locally-copied denoised HDF5.\")\n",
        "\n",
        "MAX_Y_ROWS = None  # set to None for all rows or a number for a subset\n",
        "USE_CACHE = True\n",
        "\n",
        "CACHE_DIR = Path(\".cache\")\n",
        "CACHE_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Include MAX_Y_ROWS in the cache filename so partial runs don't collide with full runs.\n",
        "max_tag = \"all\" if MAX_Y_ROWS is None else f\"rows{int(MAX_Y_ROWS)}\"\n",
        "CACHE_PATH = CACHE_DIR / (\n",
        "    f\"com_overlay_from_h5_{max_tag}_pct{COM_THRESH_PCT}_\"\n",
        "    f\"orig{Path(H5_PATH).stem}_den{Path(DENOISED_H5_PATH).stem}.npz\"\n",
        ")\n",
        "\n",
        "\n",
        "def _get_dset(f: h5py.File) -> h5py.Dataset:\n",
        "    for k in H5_KEY_CANDIDATES:\n",
        "        if k in f:\n",
        "            return f[k]\n",
        "    raise KeyError(f\"Could not find dataset key in {list(f.keys())}\")\n",
        "\n",
        "\n",
        "def _mark_com(m: np.ndarray, yc: float, xc: float) -> None:\n",
        "    if not (np.isfinite(yc) and np.isfinite(xc)):\n",
        "        return\n",
        "    iy = int(round(float(yc)))\n",
        "    ix = int(round(float(xc)))\n",
        "    if 0 <= iy < m.shape[0] and 0 <= ix < m.shape[1]:\n",
        "        m[iy, ix] = 1.0\n",
        "\n",
        "\n",
        "if USE_CACHE and CACHE_PATH.exists():\n",
        "    data = np.load(CACHE_PATH)\n",
        "    COM_MAP_INPUT_H5 = data[\"com_map_input\"]\n",
        "    COM_MAP_DENOISED_H5 = data[\"com_map_denoised\"]\n",
        "    print(\"Loaded cached CoM overlays:\", CACHE_PATH)\n",
        "else:\n",
        "    with h5py.File(H5_PATH, \"r\") as f0, h5py.File(DENOISED_H5_PATH, \"r\") as f1:\n",
        "        d0 = _get_dset(f0)\n",
        "        d1 = _get_dset(f1)\n",
        "\n",
        "        if d0.shape != d1.shape:\n",
        "            raise ValueError(f\"Shape mismatch: original={d0.shape} denoised={d1.shape}\")\n",
        "        if d0.ndim != 4:\n",
        "            raise ValueError(f\"Expected (sy,sx,H,W) datasets; got ndim={d0.ndim}\")\n",
        "\n",
        "        sy2, sx2, dety2, detx2 = (int(x) for x in d0.shape)\n",
        "        y_do = sy2 if MAX_Y_ROWS is None else min(int(MAX_Y_ROWS), sy2)\n",
        "\n",
        "        COM_MAP_INPUT_H5 = np.zeros((dety2, detx2), dtype=np.float32)\n",
        "        COM_MAP_DENOISED_H5 = np.zeros((dety2, detx2), dtype=np.float32)\n",
        "\n",
        "        y_iter = range(y_do)\n",
        "        if tqdm is not None:\n",
        "            y_iter = tqdm(y_iter, total=y_do, desc=\"CoM overlays from H5 (orig vs denoised)\")\n",
        "\n",
        "        for yy in y_iter:\n",
        "            row0 = np.asarray(d0[int(yy), :, :, :], dtype=np.float32)\n",
        "            row1 = np.asarray(d1[int(yy), :, :, :], dtype=np.float32)\n",
        "\n",
        "            for xx in range(int(sx2)):\n",
        "                yc0, xc0 = _center_of_mass_2d(_threshold_for_com(row0[xx]))\n",
        "                yc1, xc1 = _center_of_mass_2d(_threshold_for_com(row1[xx]))\n",
        "                _mark_com(COM_MAP_INPUT_H5, yc0, xc0)\n",
        "                _mark_com(COM_MAP_DENOISED_H5, yc1, xc1)\n",
        "\n",
        "    np.savez_compressed(\n",
        "        CACHE_PATH,\n",
        "        com_map_input=COM_MAP_INPUT_H5,\n",
        "        com_map_denoised=COM_MAP_DENOISED_H5,\n",
        "        orig_h5=str(H5_PATH),\n",
        "        denoised_h5=str(DENOISED_H5_PATH),\n",
        "        com_thresh_pct=np.float32(COM_THRESH_PCT),\n",
        "        max_y_rows=(-1 if MAX_Y_ROWS is None else int(MAX_Y_ROWS)),\n",
        "    )\n",
        "    print(\"Saved cached CoM overlays:\", CACHE_PATH)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 4), sharex=True, sharey=True)\n",
        "ax[0].imshow(COM_MAP_INPUT_H5, cmap=\"gray\")\n",
        "ax[0].set_title(\"CoM overlay: ORIGINAL H5\")\n",
        "ax[1].imshow(COM_MAP_DENOISED_H5, cmap=\"gray\")\n",
        "ax[1].set_title(\"CoM overlay: DENOISED H5\")\n",
        "for a in ax:\n",
        "    a.set_xticks([])\n",
        "    a.set_yticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
